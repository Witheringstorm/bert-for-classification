nohup: ignoring input
/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Using device: cuda
Using local pre-trained model from: /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/bert-base-uncased
Loading training data from: /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/data/processed/train_en.csv
Loading test data from: /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/data/processed/test_en.csv
Training data shape: (3196, 2)
Test data shape: (798, 2)

Epoch 1/5
--------------------
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:08<06:47,  8.31s/it]  4%|▍         | 2/50 [00:09<03:17,  4.11s/it]  6%|▌         | 3/50 [00:10<02:10,  2.78s/it]  8%|▊         | 4/50 [00:11<01:38,  2.14s/it] 10%|█         | 5/50 [00:12<01:20,  1.79s/it] 12%|█▏        | 6/50 [00:14<01:09,  1.57s/it] 14%|█▍        | 7/50 [00:15<01:01,  1.44s/it] 16%|█▌        | 8/50 [00:16<00:56,  1.35s/it] 18%|█▊        | 9/50 [00:17<00:52,  1.29s/it] 20%|██        | 10/50 [00:18<00:50,  1.25s/it] 22%|██▏       | 11/50 [00:19<00:47,  1.22s/it] 24%|██▍       | 12/50 [00:21<00:45,  1.21s/it] 26%|██▌       | 13/50 [00:22<00:44,  1.19s/it] 28%|██▊       | 14/50 [00:23<00:42,  1.18s/it] 30%|███       | 15/50 [00:24<00:41,  1.18s/it] 32%|███▏      | 16/50 [00:25<00:39,  1.17s/it] 34%|███▍      | 17/50 [00:26<00:38,  1.17s/it] 36%|███▌      | 18/50 [00:28<00:37,  1.17s/it] 38%|███▊      | 19/50 [00:29<00:36,  1.17s/it] 40%|████      | 20/50 [00:30<00:35,  1.17s/it] 42%|████▏     | 21/50 [00:31<00:33,  1.17s/it] 44%|████▍     | 22/50 [00:32<00:32,  1.17s/it] 46%|████▌     | 23/50 [00:33<00:31,  1.17s/it] 48%|████▊     | 24/50 [00:35<00:30,  1.17s/it] 50%|█████     | 25/50 [00:36<00:29,  1.17s/it] 52%|█████▏    | 26/50 [00:37<00:28,  1.17s/it] 54%|█████▍    | 27/50 [00:38<00:26,  1.17s/it] 56%|█████▌    | 28/50 [00:39<00:25,  1.17s/it] 58%|█████▊    | 29/50 [00:40<00:24,  1.17s/it] 60%|██████    | 30/50 [00:42<00:23,  1.17s/it] 62%|██████▏   | 31/50 [00:43<00:22,  1.17s/it] 64%|██████▍   | 32/50 [00:44<00:21,  1.17s/it] 66%|██████▌   | 33/50 [00:45<00:19,  1.17s/it] 68%|██████▊   | 34/50 [00:46<00:18,  1.17s/it] 70%|███████   | 35/50 [00:47<00:17,  1.17s/it] 72%|███████▏  | 36/50 [00:49<00:16,  1.17s/it] 74%|███████▍  | 37/50 [00:50<00:15,  1.17s/it] 76%|███████▌  | 38/50 [00:51<00:14,  1.17s/it] 78%|███████▊  | 39/50 [00:52<00:12,  1.17s/it] 80%|████████  | 40/50 [00:53<00:11,  1.17s/it] 82%|████████▏ | 41/50 [00:55<00:10,  1.17s/it] 84%|████████▍ | 42/50 [00:56<00:09,  1.17s/it] 86%|████████▌ | 43/50 [00:57<00:08,  1.17s/it] 88%|████████▊ | 44/50 [00:58<00:07,  1.18s/it] 90%|█████████ | 45/50 [00:59<00:05,  1.18s/it] 92%|█████████▏| 46/50 [01:00<00:04,  1.17s/it] 94%|█████████▍| 47/50 [01:02<00:03,  1.18s/it] 96%|█████████▌| 48/50 [01:03<00:02,  1.18s/it] 98%|█████████▊| 49/50 [01:04<00:01,  1.18s/it]100%|██████████| 50/50 [01:05<00:00,  1.15s/it]100%|██████████| 50/50 [01:05<00:00,  1.31s/it]
[LOG] Train Loss: 0.3619 | Train Accuracy: 0.8217
Evaluating on test set...
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:29,  2.45s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.23s/it] 23%|██▎       | 3/13 [00:03<00:08,  1.19it/s] 31%|███       | 4/13 [00:03<00:05,  1.52it/s] 38%|███▊      | 5/13 [00:03<00:04,  1.80it/s] 46%|████▌     | 6/13 [00:04<00:03,  2.02it/s] 54%|█████▍    | 7/13 [00:04<00:02,  2.19it/s] 62%|██████▏   | 8/13 [00:05<00:02,  2.32it/s] 69%|██████▉   | 9/13 [00:05<00:01,  2.42it/s] 77%|███████▋  | 10/13 [00:05<00:01,  2.49it/s] 85%|████████▍ | 11/13 [00:06<00:00,  2.54it/s] 92%|█████████▏| 12/13 [00:06<00:00,  2.58it/s]100%|██████████| 13/13 [00:06<00:00,  3.06it/s]100%|██████████| 13/13 [00:07<00:00,  1.83it/s]
[LOG] Test Loss: 0.2223 | Test Accuracy: 0.9135
[LOG] Test F1 (Binary for LLM class): 0.9193
[LOG] Test F1 (Macro): 0.9131
[LOG] Classification Report (Test Set):
[LOG]              precision    recall  f1-score   support

   human (0)       0.98      0.84      0.91       398
     llm (1)       0.86      0.98      0.92       400

    accuracy                           0.91       798
   macro avg       0.92      0.91      0.91       798
weighted avg       0.92      0.91      0.91       798

[LOG] Saved new best model (F1 Binary: 0.9193) to /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/models/best_model_state_en.bin

Epoch 2/5
--------------------
  0%|          | 0/50 [00:00<?, ?it/s]/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
  2%|▏         | 1/50 [00:05<04:19,  5.29s/it]  4%|▍         | 2/50 [00:06<02:23,  2.99s/it]  6%|▌         | 3/50 [00:07<01:41,  2.16s/it]  8%|▊         | 4/50 [00:09<01:21,  1.77s/it] 10%|█         | 5/50 [00:10<01:10,  1.57s/it] 12%|█▏        | 6/50 [00:11<01:03,  1.44s/it] 14%|█▍        | 7/50 [00:12<00:58,  1.35s/it] 16%|█▌        | 8/50 [00:13<00:54,  1.29s/it] 18%|█▊        | 9/50 [00:14<00:51,  1.26s/it] 20%|██        | 10/50 [00:16<00:49,  1.23s/it] 22%|██▏       | 11/50 [00:17<00:47,  1.21s/it] 24%|██▍       | 12/50 [00:18<00:45,  1.20s/it] 26%|██▌       | 13/50 [00:19<00:44,  1.19s/it] 28%|██▊       | 14/50 [00:20<00:42,  1.19s/it] 30%|███       | 15/50 [00:21<00:41,  1.19s/it] 32%|███▏      | 16/50 [00:23<00:40,  1.18s/it] 34%|███▍      | 17/50 [00:24<00:38,  1.18s/it] 36%|███▌      | 18/50 [00:25<00:37,  1.18s/it] 38%|███▊      | 19/50 [00:26<00:36,  1.18s/it] 40%|████      | 20/50 [00:27<00:35,  1.18s/it] 42%|████▏     | 21/50 [00:29<00:34,  1.18s/it] 44%|████▍     | 22/50 [00:30<00:33,  1.18s/it] 46%|████▌     | 23/50 [00:31<00:31,  1.18s/it] 48%|████▊     | 24/50 [00:32<00:30,  1.18s/it] 50%|█████     | 25/50 [00:33<00:29,  1.18s/it] 52%|█████▏    | 26/50 [00:34<00:28,  1.18s/it] 54%|█████▍    | 27/50 [00:36<00:27,  1.18s/it] 56%|█████▌    | 28/50 [00:37<00:25,  1.18s/it] 58%|█████▊    | 29/50 [00:38<00:24,  1.18s/it] 60%|██████    | 30/50 [00:39<00:23,  1.18s/it] 62%|██████▏   | 31/50 [00:40<00:22,  1.18s/it] 64%|██████▍   | 32/50 [00:42<00:21,  1.18s/it] 66%|██████▌   | 33/50 [00:43<00:20,  1.18s/it] 68%|██████▊   | 34/50 [00:44<00:18,  1.18s/it] 70%|███████   | 35/50 [00:45<00:17,  1.18s/it] 72%|███████▏  | 36/50 [00:46<00:16,  1.18s/it] 74%|███████▍  | 37/50 [00:47<00:15,  1.18s/it] 76%|███████▌  | 38/50 [00:49<00:14,  1.18s/it] 78%|███████▊  | 39/50 [00:50<00:12,  1.18s/it] 80%|████████  | 40/50 [00:51<00:11,  1.18s/it] 82%|████████▏ | 41/50 [00:52<00:10,  1.18s/it] 84%|████████▍ | 42/50 [00:53<00:09,  1.18s/it] 86%|████████▌ | 43/50 [00:54<00:08,  1.18s/it] 88%|████████▊ | 44/50 [00:56<00:07,  1.18s/it] 90%|█████████ | 45/50 [00:57<00:05,  1.18s/it] 92%|█████████▏| 46/50 [00:58<00:04,  1.18s/it] 94%|█████████▍| 47/50 [00:59<00:03,  1.18s/it] 96%|█████████▌| 48/50 [01:00<00:02,  1.18s/it] 98%|█████████▊| 49/50 [01:02<00:01,  1.18s/it]100%|██████████| 50/50 [01:03<00:00,  1.16s/it]100%|██████████| 50/50 [01:03<00:00,  1.27s/it]
[LOG] Train Loss: 0.1022 | Train Accuracy: 0.9625
Evaluating on test set...
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:30,  2.53s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.26s/it] 23%|██▎       | 3/13 [00:03<00:08,  1.17it/s] 31%|███       | 4/13 [00:03<00:06,  1.49it/s] 38%|███▊      | 5/13 [00:04<00:04,  1.77it/s] 46%|████▌     | 6/13 [00:04<00:03,  2.00it/s] 54%|█████▍    | 7/13 [00:04<00:02,  2.18it/s] 62%|██████▏   | 8/13 [00:05<00:02,  2.31it/s] 69%|██████▉   | 9/13 [00:05<00:01,  2.41it/s] 77%|███████▋  | 10/13 [00:05<00:01,  2.48it/s] 85%|████████▍ | 11/13 [00:06<00:00,  2.53it/s] 92%|█████████▏| 12/13 [00:06<00:00,  2.57it/s]100%|██████████| 13/13 [00:06<00:00,  3.06it/s]100%|██████████| 13/13 [00:07<00:00,  1.81it/s]
[LOG] Test Loss: 0.0505 | Test Accuracy: 0.9837
[LOG] Test F1 (Binary for LLM class): 0.9836
[LOG] Test F1 (Macro): 0.9837
[LOG] Classification Report (Test Set):
[LOG]              precision    recall  f1-score   support

   human (0)       0.98      0.99      0.98       398
     llm (1)       0.99      0.97      0.98       400

    accuracy                           0.98       798
   macro avg       0.98      0.98      0.98       798
weighted avg       0.98      0.98      0.98       798

[LOG] Saved new best model (F1 Binary: 0.9836) to /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/models/best_model_state_en.bin

Epoch 3/5
--------------------
  0%|          | 0/50 [00:00<?, ?it/s]/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
  2%|▏         | 1/50 [00:05<04:29,  5.50s/it]  4%|▍         | 2/50 [00:06<02:25,  3.04s/it]  6%|▌         | 3/50 [00:07<01:42,  2.19s/it]  8%|▊         | 4/50 [00:09<01:22,  1.79s/it] 10%|█         | 5/50 [00:10<01:10,  1.57s/it] 12%|█▏        | 6/50 [00:11<01:03,  1.44s/it] 14%|█▍        | 7/50 [00:12<00:58,  1.35s/it] 16%|█▌        | 8/50 [00:13<00:54,  1.30s/it] 18%|█▊        | 9/50 [00:15<00:51,  1.26s/it] 20%|██        | 10/50 [00:16<00:49,  1.23s/it] 22%|██▏       | 11/50 [00:17<00:47,  1.22s/it] 24%|██▍       | 12/50 [00:18<00:45,  1.20s/it] 26%|██▌       | 13/50 [00:19<00:44,  1.20s/it] 28%|██▊       | 14/50 [00:20<00:42,  1.19s/it] 30%|███       | 15/50 [00:22<00:41,  1.19s/it] 32%|███▏      | 16/50 [00:23<00:40,  1.18s/it] 34%|███▍      | 17/50 [00:24<00:39,  1.18s/it] 36%|███▌      | 18/50 [00:25<00:37,  1.18s/it] 38%|███▊      | 19/50 [00:26<00:36,  1.18s/it] 40%|████      | 20/50 [00:28<00:35,  1.18s/it] 42%|████▏     | 21/50 [00:29<00:34,  1.18s/it] 44%|████▍     | 22/50 [00:30<00:33,  1.18s/it] 46%|████▌     | 23/50 [00:31<00:31,  1.18s/it] 48%|████▊     | 24/50 [00:32<00:30,  1.18s/it] 50%|█████     | 25/50 [00:33<00:29,  1.18s/it] 52%|█████▏    | 26/50 [00:35<00:28,  1.18s/it] 54%|█████▍    | 27/50 [00:36<00:27,  1.18s/it] 56%|█████▌    | 28/50 [00:37<00:25,  1.18s/it] 58%|█████▊    | 29/50 [00:38<00:24,  1.18s/it] 60%|██████    | 30/50 [00:39<00:23,  1.18s/it] 62%|██████▏   | 31/50 [00:40<00:22,  1.18s/it] 64%|██████▍   | 32/50 [00:42<00:21,  1.18s/it] 66%|██████▌   | 33/50 [00:43<00:20,  1.18s/it] 68%|██████▊   | 34/50 [00:44<00:18,  1.18s/it] 70%|███████   | 35/50 [00:45<00:17,  1.18s/it] 72%|███████▏  | 36/50 [00:46<00:16,  1.18s/it] 74%|███████▍  | 37/50 [00:48<00:15,  1.18s/it] 76%|███████▌  | 38/50 [00:49<00:14,  1.18s/it] 78%|███████▊  | 39/50 [00:50<00:12,  1.18s/it] 80%|████████  | 40/50 [00:51<00:11,  1.18s/it] 82%|████████▏ | 41/50 [00:52<00:10,  1.18s/it] 84%|████████▍ | 42/50 [00:53<00:09,  1.18s/it] 86%|████████▌ | 43/50 [00:55<00:08,  1.18s/it] 88%|████████▊ | 44/50 [00:56<00:07,  1.18s/it] 90%|█████████ | 45/50 [00:57<00:05,  1.18s/it] 92%|█████████▏| 46/50 [00:58<00:04,  1.18s/it] 94%|█████████▍| 47/50 [00:59<00:03,  1.18s/it] 96%|█████████▌| 48/50 [01:01<00:02,  1.18s/it] 98%|█████████▊| 49/50 [01:02<00:01,  1.18s/it]100%|██████████| 50/50 [01:03<00:00,  1.16s/it]100%|██████████| 50/50 [01:03<00:00,  1.27s/it]
[LOG] Train Loss: 0.0213 | Train Accuracy: 0.9931
Evaluating on test set...
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:30,  2.53s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.26s/it] 23%|██▎       | 3/13 [00:03<00:08,  1.16it/s] 31%|███       | 4/13 [00:03<00:06,  1.49it/s] 38%|███▊      | 5/13 [00:04<00:04,  1.77it/s] 46%|████▌     | 6/13 [00:04<00:03,  2.00it/s] 54%|█████▍    | 7/13 [00:04<00:02,  2.17it/s] 62%|██████▏   | 8/13 [00:05<00:02,  2.31it/s] 69%|██████▉   | 9/13 [00:05<00:01,  2.41it/s] 77%|███████▋  | 10/13 [00:05<00:01,  2.48it/s] 85%|████████▍ | 11/13 [00:06<00:00,  2.53it/s] 92%|█████████▏| 12/13 [00:06<00:00,  2.57it/s]100%|██████████| 13/13 [00:06<00:00,  3.05it/s]100%|██████████| 13/13 [00:07<00:00,  1.80it/s]
[LOG] Test Loss: 0.0876 | Test Accuracy: 0.9749
[LOG] Test F1 (Binary for LLM class): 0.9755
[LOG] Test F1 (Macro): 0.9749
[LOG] Classification Report (Test Set):
[LOG]              precision    recall  f1-score   support

   human (0)       0.99      0.95      0.97       398
     llm (1)       0.96      0.99      0.98       400

    accuracy                           0.97       798
   macro avg       0.98      0.97      0.97       798
weighted avg       0.98      0.97      0.97       798


Epoch 4/5
--------------------
  0%|          | 0/50 [00:00<?, ?it/s]/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
  2%|▏         | 1/50 [00:05<04:26,  5.43s/it]  4%|▍         | 2/50 [00:06<02:26,  3.06s/it]  6%|▌         | 3/50 [00:08<01:44,  2.22s/it]  8%|▊         | 4/50 [00:09<01:23,  1.81s/it] 10%|█         | 5/50 [00:10<01:11,  1.58s/it] 12%|█▏        | 6/50 [00:11<01:03,  1.44s/it] 14%|█▍        | 7/50 [00:12<00:58,  1.36s/it] 16%|█▌        | 8/50 [00:13<00:54,  1.30s/it] 18%|█▊        | 9/50 [00:15<00:51,  1.26s/it] 20%|██        | 10/50 [00:16<00:49,  1.24s/it] 22%|██▏       | 11/50 [00:17<00:47,  1.22s/it] 24%|██▍       | 12/50 [00:18<00:45,  1.21s/it] 26%|██▌       | 13/50 [00:19<00:44,  1.20s/it] 28%|██▊       | 14/50 [00:21<00:43,  1.19s/it] 30%|███       | 15/50 [00:22<00:41,  1.19s/it] 32%|███▏      | 16/50 [00:23<00:40,  1.19s/it] 34%|███▍      | 17/50 [00:24<00:39,  1.19s/it] 36%|███▌      | 18/50 [00:25<00:37,  1.18s/it] 38%|███▊      | 19/50 [00:26<00:36,  1.18s/it] 40%|████      | 20/50 [00:28<00:35,  1.18s/it] 42%|████▏     | 21/50 [00:29<00:34,  1.18s/it] 44%|████▍     | 22/50 [00:30<00:33,  1.18s/it] 46%|████▌     | 23/50 [00:31<00:31,  1.18s/it] 48%|████▊     | 24/50 [00:32<00:30,  1.18s/it] 50%|█████     | 25/50 [00:34<00:29,  1.18s/it] 52%|█████▏    | 26/50 [00:35<00:28,  1.18s/it] 54%|█████▍    | 27/50 [00:36<00:27,  1.18s/it] 56%|█████▌    | 28/50 [00:37<00:25,  1.18s/it] 58%|█████▊    | 29/50 [00:38<00:24,  1.18s/it] 60%|██████    | 30/50 [00:39<00:23,  1.18s/it] 62%|██████▏   | 31/50 [00:41<00:22,  1.18s/it] 64%|██████▍   | 32/50 [00:42<00:21,  1.18s/it] 66%|██████▌   | 33/50 [00:43<00:20,  1.18s/it] 68%|██████▊   | 34/50 [00:44<00:18,  1.18s/it] 70%|███████   | 35/50 [00:45<00:17,  1.18s/it] 72%|███████▏  | 36/50 [00:46<00:16,  1.18s/it] 74%|███████▍  | 37/50 [00:48<00:15,  1.18s/it] 76%|███████▌  | 38/50 [00:49<00:14,  1.18s/it] 78%|███████▊  | 39/50 [00:50<00:13,  1.18s/it] 80%|████████  | 40/50 [00:51<00:11,  1.18s/it] 82%|████████▏ | 41/50 [00:52<00:10,  1.18s/it] 84%|████████▍ | 42/50 [00:54<00:09,  1.18s/it] 86%|████████▌ | 43/50 [00:55<00:08,  1.18s/it] 88%|████████▊ | 44/50 [00:56<00:07,  1.18s/it] 90%|█████████ | 45/50 [00:57<00:05,  1.18s/it] 92%|█████████▏| 46/50 [00:58<00:04,  1.18s/it] 94%|█████████▍| 47/50 [00:59<00:03,  1.18s/it] 96%|█████████▌| 48/50 [01:01<00:02,  1.18s/it] 98%|█████████▊| 49/50 [01:02<00:01,  1.18s/it]100%|██████████| 50/50 [01:03<00:00,  1.16s/it]100%|██████████| 50/50 [01:03<00:00,  1.28s/it]
[LOG] Train Loss: 0.0018 | Train Accuracy: 0.9997
Evaluating on test set...
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:30,  2.55s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.27s/it] 23%|██▎       | 3/13 [00:03<00:08,  1.16it/s] 31%|███       | 4/13 [00:03<00:06,  1.49it/s] 38%|███▊      | 5/13 [00:04<00:04,  1.77it/s] 46%|████▌     | 6/13 [00:04<00:03,  1.99it/s] 54%|█████▍    | 7/13 [00:04<00:02,  2.17it/s] 62%|██████▏   | 8/13 [00:05<00:02,  2.30it/s] 69%|██████▉   | 9/13 [00:05<00:01,  2.40it/s] 77%|███████▋  | 10/13 [00:05<00:01,  2.47it/s] 85%|████████▍ | 11/13 [00:06<00:00,  2.53it/s] 92%|█████████▏| 12/13 [00:06<00:00,  2.56it/s]100%|██████████| 13/13 [00:06<00:00,  3.05it/s]100%|██████████| 13/13 [00:07<00:00,  1.80it/s]
[LOG] Test Loss: 0.0653 | Test Accuracy: 0.9862
[LOG] Test F1 (Binary for LLM class): 0.9863
[LOG] Test F1 (Macro): 0.9862
[LOG] Classification Report (Test Set):
[LOG]              precision    recall  f1-score   support

   human (0)       0.99      0.98      0.99       398
     llm (1)       0.98      0.99      0.99       400

    accuracy                           0.99       798
   macro avg       0.99      0.99      0.99       798
weighted avg       0.99      0.99      0.99       798

[LOG] Saved new best model (F1 Binary: 0.9863) to /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/models/best_model_state_en.bin

Epoch 5/5
--------------------
  0%|          | 0/50 [00:00<?, ?it/s]/public/home/qinxiaoyu/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
  2%|▏         | 1/50 [00:05<04:17,  5.25s/it]  4%|▍         | 2/50 [00:06<02:26,  3.05s/it]  6%|▌         | 3/50 [00:07<01:44,  2.22s/it]  8%|▊         | 4/50 [00:09<01:23,  1.81s/it] 10%|█         | 5/50 [00:10<01:11,  1.58s/it] 12%|█▏        | 6/50 [00:11<01:03,  1.44s/it] 14%|█▍        | 7/50 [00:12<00:58,  1.37s/it] 16%|█▌        | 8/50 [00:13<00:54,  1.31s/it] 18%|█▊        | 9/50 [00:15<00:51,  1.27s/it] 20%|██        | 10/50 [00:16<00:49,  1.24s/it] 22%|██▏       | 11/50 [00:17<00:47,  1.22s/it] 24%|██▍       | 12/50 [00:18<00:45,  1.21s/it] 26%|██▌       | 13/50 [00:19<00:44,  1.20s/it] 28%|██▊       | 14/50 [00:20<00:42,  1.19s/it] 30%|███       | 15/50 [00:22<00:41,  1.19s/it] 32%|███▏      | 16/50 [00:23<00:40,  1.18s/it] 34%|███▍      | 17/50 [00:24<00:39,  1.18s/it] 36%|███▌      | 18/50 [00:25<00:37,  1.18s/it] 38%|███▊      | 19/50 [00:26<00:36,  1.18s/it] 40%|████      | 20/50 [00:28<00:35,  1.18s/it] 42%|████▏     | 21/50 [00:29<00:34,  1.18s/it] 44%|████▍     | 22/50 [00:30<00:33,  1.18s/it] 46%|████▌     | 23/50 [00:31<00:31,  1.18s/it] 48%|████▊     | 24/50 [00:32<00:30,  1.18s/it] 50%|█████     | 25/50 [00:33<00:29,  1.18s/it] 52%|█████▏    | 26/50 [00:35<00:28,  1.18s/it] 54%|█████▍    | 27/50 [00:36<00:27,  1.18s/it] 56%|█████▌    | 28/50 [00:37<00:25,  1.18s/it] 58%|█████▊    | 29/50 [00:38<00:24,  1.18s/it] 60%|██████    | 30/50 [00:39<00:23,  1.18s/it] 62%|██████▏   | 31/50 [00:41<00:22,  1.18s/it] 64%|██████▍   | 32/50 [00:42<00:21,  1.18s/it] 66%|██████▌   | 33/50 [00:43<00:20,  1.18s/it] 68%|██████▊   | 34/50 [00:44<00:18,  1.18s/it] 70%|███████   | 35/50 [00:45<00:17,  1.18s/it] 72%|███████▏  | 36/50 [00:46<00:16,  1.18s/it] 74%|███████▍  | 37/50 [00:48<00:15,  1.18s/it] 76%|███████▌  | 38/50 [00:49<00:14,  1.18s/it] 78%|███████▊  | 39/50 [00:50<00:13,  1.18s/it] 80%|████████  | 40/50 [00:51<00:11,  1.18s/it] 82%|████████▏ | 41/50 [00:52<00:10,  1.18s/it] 84%|████████▍ | 42/50 [00:54<00:09,  1.18s/it] 86%|████████▌ | 43/50 [00:55<00:08,  1.18s/it] 88%|████████▊ | 44/50 [00:56<00:07,  1.18s/it] 90%|█████████ | 45/50 [00:57<00:05,  1.18s/it] 92%|█████████▏| 46/50 [00:58<00:04,  1.18s/it] 94%|█████████▍| 47/50 [00:59<00:03,  1.18s/it] 96%|█████████▌| 48/50 [01:01<00:02,  1.18s/it] 98%|█████████▊| 49/50 [01:02<00:01,  1.18s/it]100%|██████████| 50/50 [01:03<00:00,  1.16s/it]100%|██████████| 50/50 [01:03<00:00,  1.28s/it]
[LOG] Train Loss: 0.0018 | Train Accuracy: 0.9997
Evaluating on test set...
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:30,  2.54s/it] 15%|█▌        | 2/13 [00:02<00:13,  1.27s/it] 23%|██▎       | 3/13 [00:03<00:08,  1.16it/s] 31%|███       | 4/13 [00:03<00:06,  1.49it/s] 38%|███▊      | 5/13 [00:04<00:04,  1.77it/s] 46%|████▌     | 6/13 [00:04<00:03,  2.00it/s] 54%|█████▍    | 7/13 [00:04<00:02,  2.17it/s] 62%|██████▏   | 8/13 [00:05<00:02,  2.30it/s] 69%|██████▉   | 9/13 [00:05<00:01,  2.40it/s] 77%|███████▋  | 10/13 [00:05<00:01,  2.48it/s] 85%|████████▍ | 11/13 [00:06<00:00,  2.53it/s] 92%|█████████▏| 12/13 [00:06<00:00,  2.56it/s]100%|██████████| 13/13 [00:06<00:00,  3.05it/s]100%|██████████| 13/13 [00:07<00:00,  1.80it/s]
[LOG] Test Loss: 0.0918 | Test Accuracy: 0.9774
[LOG] Test F1 (Binary for LLM class): 0.9778
[LOG] Test F1 (Macro): 0.9774
[LOG] Classification Report (Test Set):
[LOG]              precision    recall  f1-score   support

   human (0)       0.99      0.96      0.98       398
     llm (1)       0.96      0.99      0.98       400

    accuracy                           0.98       798
   macro avg       0.98      0.98      0.98       798
weighted avg       0.98      0.98      0.98       798


Training complete.
[LOG] Best F1-score (Binary for LLM class) on Test Set: 0.9863
[LOG] Saved all epoch results to /public/share/yinxiangrong/qinxiaoyu/kdc2024/S/nlp/proj/bert_en/models/all_epochs_results_en.json
